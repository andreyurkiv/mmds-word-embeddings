{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import os\n",
    "# os.environ['PYSPARK_PYTHON'] = '/usr/bin/python3'\n",
    "# os.environ[\"PYSPARK_PYTHON\"] = \"/home/serhii/anaconda3/bin/python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/ukwiki_0.csv\"\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"WikiParse\").getOrCreate()\n",
    "\n",
    "df = spark.read.csv(file, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "\n",
    "with open('data/stop_words') as file:\n",
    "    for line in file:\n",
    "        stop_words.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trip = df.select(['Title', 'Text'])\\\n",
    "    .withColumn('Text', regexp_replace('Text', '[§»«·&\\~.a-zA-Z^=\\-\\\"<>!?:;{}()\\[\\]/|%0-9\\\\\\+\\*#_]+', ' '))\\\n",
    "    .withColumn('Text', regexp_replace('Text', '\\'{3}', ' '))\\\n",
    "    .withColumn('Text', regexp_replace('Text', '[—−]', ' '))\\\n",
    "    .withColumn('Text', regexp_replace('Text', '[^а-яА-ЯіІіІєЄҐґїЇ\\s]', ''))\\\n",
    "    .withColumn('Text', regexp_replace('Text', '\\s+', ' '))\\\n",
    "    .select([trim(lower(col('Title'))).alias('Title'), trim(lower(col('Text'))).alias('Text')])\\\n",
    "\n",
    "#     .withColumn(\"Text\", split(\"Text\", \"\\s+\"))\n",
    "#     .withColumn('Text', regexp_replace('Text', '[òо́]', 'о'))\\\n",
    "#     .withColumn('Text', regexp_replace('Text', 'а́', 'а'))\\\n",
    "#     .withColumn('Text', regexp_replace('Text', 'í', 'і'))\\\n",
    "#     .withColumn('Text', regexp_replace('Text', 'и́', 'и'))\\\n",
    "#     .withColumn('Text', regexp_replace('Text', '[е́é]', 'е'))\\\n",
    "#     .withColumn('Text', regexp_replace('Text', '[́м]', 'м'))\\\n",
    "#     .withColumn('Text', regexp_replace('Text', '\\'', ''))\\\n",
    "#     .withColumn('Text', regexp_replace('Text', '[α-ωΑ-Ωºäüöñ¹²³⁴]+', ''))\\\n",
    "#     .withColumn('Text', regexp_replace('Text', '\\s+', ' '))\\\n",
    "#     .select([trim(lower(col('Title'))), trim(lower(col('Text')))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"Text\", outputCol=\"Vector\")\n",
    "\n",
    "vector_df = tokenizer.transform(df_trip).select(\"vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              vector|\n",
      "+--------------------+\n",
      "|[шапка, головна, ...|\n",
      "|[файл, фізична, к...|\n",
      "|[атом, значення, ...|\n",
      "|[мільярд, число, ...|\n",
      "|[ядро, основна, ч...|\n",
      "|[файл, пкс, римсь...|\n",
      "|[файл, хімічні, р...|\n",
      "|[файл, коло, з, ц...|\n",
      "|[файл, міжнародни...|\n",
      "|[біологія, життя,...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'б', 'в', 'г', 'е', 'ж', 'з', 'м', 'т', 'у']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol=\"vector\", outputCol=\"vector_no_stopwords\" ,stopWords=stop_words)\n",
    "\n",
    "stopwords = remover.getStopWords() \n",
    "\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_no_stopw_df = remover.transform(vector_df).select(\"vector_no_stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| vector_no_stopwords|\n",
      "+--------------------+\n",
      "|[шапка, головна, ...|\n",
      "|[файл, фізична, к...|\n",
      "|[атом, значення, ...|\n",
      "|[мільярд, число, ...|\n",
      "|[ядро, основна, ч...|\n",
      "|[файл, пкс, римсь...|\n",
      "|[файл, хімічні, р...|\n",
      "|[файл, коло, цент...|\n",
      "|[файл, міжнародни...|\n",
      "|[біологія, слово,...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vector_no_stopw_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class UkrainianStemmer():\n",
    "    def __init__(self, word):\n",
    "        self.word = word\n",
    "        self.vowel = r'аеиоуюяіїє'  # http://uk.wikipedia.org/wiki/Голосний_звук\n",
    "        self.perfectiveground = r'(ив|ивши|ившись|ыв|ывши|ывшись((?<=[ая])(в|вши|вшись)))$'\n",
    "        # http://uk.wikipedia.org/wiki/Рефлексивне_дієслово\n",
    "        self.reflexive = r'(с[яьи])$'\n",
    "        # http://uk.wikipedia.org/wiki/Прикметник + http://wapedia.mobi/uk/Прикметник\n",
    "        self.adjective = r'(ими|ій|ий|а|е|ова|ове|ів|є|їй|єє|еє|я|ім|ем|им|ім|их|іх|ою|йми|іми|у|ю|ого|ому|ої)$'\n",
    "        # http://uk.wikipedia.org/wiki/Дієприкметник\n",
    "        self.participle = r'(ий|ого|ому|им|ім|а|ій|у|ою|ій|і|их|йми|их)$'\n",
    "        # http://uk.wikipedia.org/wiki/Дієслово\n",
    "        self.verb = r'(сь|ся|ив|ать|ять|у|ю|ав|али|учи|ячи|вши|ши|е|ме|ати|яти|є)$'\n",
    "        # http://uk.wikipedia.org/wiki/Іменник\n",
    "        self.noun = r'(а|ев|ов|е|ями|ами|еи|и|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я|і|ові|ї|ею|єю|ою|є|еві|ем|єм|ів|їв|ю)$'\n",
    "        self.rvre = r'[аеиоуюяіїє]'\n",
    "        self.derivational = r'[^аеиоуюяіїє][аеиоуюяіїє]+[^аеиоуюяіїє]+[аеиоуюяіїє].*(?<=о)сть?$'\n",
    "        self.RV = ''\n",
    "\n",
    "    def ukstemmer_search_preprocess(self, word):\n",
    "        word = word.lower()\n",
    "        word = word.replace(\"'\", \"\")\n",
    "        word = word.replace(\"ё\", \"е\")\n",
    "        word = word.replace(\"ъ\", \"ї\")\n",
    "        return word\n",
    "\n",
    "    def s(self, st, reg, to):\n",
    "        orig = st\n",
    "        self.RV = re.sub(reg, to, st)\n",
    "        return (orig != self.RV)\n",
    "\n",
    "    def stem_word(self):\n",
    "        word = self.ukstemmer_search_preprocess(self.word)\n",
    "        if not re.search('[аеиоуюяіїє]', word):\n",
    "            stem = word\n",
    "        else:\n",
    "            p = re.search(self.rvre, word)\n",
    "            start = word[0:p.span()[1]]\n",
    "            self.RV = word[p.span()[1]:]\n",
    "\n",
    "            # Step 1\n",
    "            if not self.s(self.RV, self.perfectiveground, ''):\n",
    "\n",
    "                self.s(self.RV, self.reflexive, '')\n",
    "                if self.s(self.RV, self.adjective, ''):\n",
    "                    self.s(self.RV, self.participle, '')\n",
    "                else:\n",
    "                    if not self.s(self.RV, self.verb, ''):\n",
    "                        self.s(self.RV, self.noun, '')\n",
    "            # Step 2\n",
    "            self.s(self.RV, 'и$', '')\n",
    "\n",
    "            # Step 3\n",
    "            if re.search(self.derivational, self.RV):\n",
    "                self.s(self.RV, 'ость$', '')\n",
    "\n",
    "            # Step 4\n",
    "            if self.s(self.RV, 'ь$', ''):\n",
    "                self.s(self.RV, 'ейше?$', '')\n",
    "                self.s(self.RV, 'нн$', u'н')\n",
    "\n",
    "            stem = start + self.RV\n",
    "        return stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(in_vec):\n",
    "    out_vec = []\n",
    "    for t in in_vec:\n",
    "        t_stem = UkrainianStemmer(t).stem_word()\n",
    "        if len(t_stem) > 2:\n",
    "            out_vec.append(t_stem)       \n",
    "    return out_vec\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "stemmer_udf = udf(lambda x: stem(x), ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_stemmed_df = (\n",
    "    vector_no_stopw_df\n",
    "        .withColumn(\"vector_stemmed\", stemmer_udf(\"vector_no_stopwords\"))\n",
    "        .select(\"vector_stemmed\")\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_str(in_vec):\n",
    "    return \" \".join([w for w in in_vec])\n",
    "\n",
    "list_to_str_udf = udf(lambda x: list_to_str(x), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vector_stemmed_df.withColumn('Text', list_to_str_udf('vector_stemmed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['Text'].to_csv('preproc_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[vector_stemmed: array<string>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_stemmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec = Word2Vec(vectorSize=100, seed=42, inputCol='vector_stemmed', outputCol='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = word2Vec.fit(vector_stemmed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = model.getVectors()\n",
    "size = 100\n",
    "amount = vectors.count()\n",
    "\n",
    "vectors_collection = vectors.collect()\n",
    "\n",
    "f = open('custom.embeddings', 'w')\n",
    "\n",
    "f.write('{} {}\\n'.format(amount, size))\n",
    "\n",
    "for row in vectors_collection:\n",
    "    vec_str = ' '.join([ str(np.round(x, 5)) for x in row['vector']])\n",
    "    f.write(row['word'] + ' ' + vec_str + '\\n')\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(w2v_model, file_name):\n",
    "    vectors = w2v_model.getVectors()\n",
    "    size = len(vectors.first()['vector'])\n",
    "    amount = vectors.count()\n",
    "\n",
    "    vectors_collection = vectors.collect()\n",
    "\n",
    "    f = open(file_name, 'w')\n",
    "\n",
    "    f.write('{} {}\\n'.format(amount, size))\n",
    "\n",
    "    for row in vectors_collection:\n",
    "        vec_str = ' '.join([ str(np.round(x, 5)) for x in row['vector']])\n",
    "        f.write(row['word'] + ' ' + vec_str + '\\n')\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "save_model(model, 'custom.embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/serhii/anaconda3/lib/python3.7/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "gmodel = gensim.models.KeyedVectors.load_word2vec_format(\"custom.embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('київ', 1.0),\n",
       " ('всеукр', 0.8452724814414978),\n",
       " ('шубравськ', 0.8207768201828003),\n",
       " ('бібліотечк', 0.8139780163764954),\n",
       " ('шевченкознавч', 0.8110851049423218),\n",
       " ('петраш', 0.8075677752494812),\n",
       " ('печатн', 0.8074122071266174),\n",
       " ('соціол', 0.7977311611175537),\n",
       " ('пядесят', 0.7971876859664917),\n",
       " ('одмін', 0.796441912651062)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmodel.similar_by_vector(gmodel['київ'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
